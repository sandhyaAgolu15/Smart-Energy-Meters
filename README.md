# Smart-Energy-Meters
This project utilizes Azure IoT Hub, Stream Analytics, Event Hub, and Logic Apps to process real-time data from smart meters and trigger actions based on anomalies. The project also uses Blob Storage and Azure Machine Learning to forecast electricity consumption for the next 24 hours.

## Data Sources:
Smart meters are connected to the internet and it helps the data to be transmitted to a central database for analysis. The data generated by smart meters is becoming an increasingly valuable asset of information for researchers, consumers and providers.


<img width="466" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/eee30b1c-503c-40bd-823c-c26749f2476f">



1. The smart meter distributor will have a list of all the devices with its ID. The list will be provided to the Device Provisioning Service (DPS).
2. Device will try to contact the DPS. Then the DPS will search the device id into a list and if the device ID is present. Then it will add that into the enrollment list.
3. DPS will send details back to the device.
4. DPS will send that id to the IoT Hub.
5. IoT Hub will register the device and create a space to store the data related to this device. It sends back the details to the DPS system.
6. DPS will send the details back to device and the device is connected to IoT Hub
7. The device will make a connection with the IDs.
8. The device will send real time data to IoT Hub.



Once the devices are successfully registered starts generating real-time data that closely mimics the patterns and characteristics of real-world smart meter data. The data will look like Fig. Data collected from Simulated smart meters. It will be having three different features Device ID, Temperature, and Time Stamp.



<img width="288" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/0e3857d6-53f6-49ae-b728-aa18c5f5c06d">




## ETL (Data Extraction, Transformation, Loading)

Extract:
As now you know the data source and what type of data we are collecting. We are collecting real-time data from simulated six smart meters.

Transform/Data Cleaning:
We are getting the data in JSON format. So first we are transforming that data into a .csv file on Databricks. We need to clean the data. Our data is mostly clean but here we have one field Timestamp. Inside this field we have date and time (YYYY:MM:DDTHH:MM:SS). We are separating the time and date. We added a new column as day for this column and we fetched values using the date which we separated. Using the time column, we are taking data hourly.

Load:
Once the data is transformed into the .csv file we load that data into the Azure Blob Storage




<img width="437" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/e23f7cbd-0fc7-49ef-a9e2-3ca6b2d153f2">




## Data architecture
A project using Azure to implement smart power meters has a sophisticated architecture comprising several interdependent parts.



Smart Meters:

The smart meters, the IoT Hub, Stream Analytics, Power BI, Azure Storage, Azure Databricks, and Gmail alerts utilizing Azure logic applications will all be covered in this paper, along with other elements of this architecture. The smart meters, which are linked to the internet, are the initial part of this architecture. Smart meters are devices that monitor and gather data on client energy usage, giving both the consumer and the power supplier information about energy consumption.



<img width="449" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/727f8203-9d59-4bc5-bb87-04f80baa5b38">





IoT Hub:

The first step in the process is to simulate smart meters that collect and send energy consumption data to Azure IoT Hub. IoT Hub is a cloud-based platform that enables bi-directional communication between devices and the cloud. It is a scalable and secure platform that supports various protocols such as MQTT, AMQP, and HTTPS. The smart meters are configured to send data to IoT Hub using the HTTPS protocol.




<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/bcd984b4-340e-4884-a0ad-bdf7bc50a537">





In this project, the smart meters that are transmitting real-time data interact with Azure IoT Hub. The image below shows the devices registered in the IoT hub. 

Stream Analytics:

Hot Stream:
In the process is to use Azure Stream Analytics to process the incoming data from IoT Hub. Stream Analytics is a real-time data processing service that can ingest, process, and analyze data streams in real-time. It supports a wide range of data sources, including IoT Hub, Event Hub, and Blob Storage. In this project, we use Stream Analytics to process the stream of data from the smart meters and transform it into a real-time data stream that is sent to a PowerBI dashboard. This data stream is referred to as the "hot stream" which has 3 things called nput, sql query and output which will be transferred to the power BI dashboard. Data from the IoT Hub is ingested into Azure Stream Analytics, processed, and finally, the result is sent to Power BI. IoT Hub data was initially fed into Azure Stream Analytics. 


Stream Analytics Input:




<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/60f80a09-aa23-4063-8b13-6680a766479d">




Stream Analytics Output:


<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/12460892-1ca1-487e-a29e-835fd51a2ef7">



The data was then processed and examined using unique SQL queries. Real-time data filtering, aggregation, and transformation are all possible with these queries. As a consequence, the user may swiftly draw conclusions from the data and take action in light of the findings. 



Stream Analytics Query:



<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/510420e3-be9c-4ea4-8624-0b9ed19111ec">






The result from data processing and analysis may be forwarded to Power BI for visualization. Users may quickly and simply build interactive representations with Power BI, a robust data visualization tool. 

This makes data exploration simple and makes it quicker for the user to understand their data. By doing this, users can discover more about their data and make choices on the findings.




Power BI:

The data is then transferred to Power BI for clients, so they can make informed decisions. A business intelligence software called Power BI offers interactive dashboards and representations. Where the user can monitor electricity usage fluctuations in real-time and decide how much power to consume. He may also determine which home appliances are consuming more power thanks to the real-time dashboard. This enables users to better understand consumer energy use by gaining insights into the data gathered from the smart meters.



<img width="433" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/9d5d7c0a-4572-4d5e-9f25-d2054dbab1af">




The key KPIs that are captured in the dashboard is as follows:
Power Consumption: Total power consumed by all the captivated devices.
Maximum Temperature: The maximum temperature recorded so far within the available devices.
Minimum Temperature: The minimum temperature recorded so far within the available devices.
Power Consumption of each device: Individual power consumption of each device
Temperature of each device: Individual temperature of each device
Power Consumption & Temperature Readings per second: Real time data capturing power consumption and temperature per second value.


Cold Stream:

Azure Storage:

In this step is to store the incoming data in Blob Storage for later use in forecasting. Blob Storage is a cloud-based object storage service that can store large amounts of unstructured data. The incoming data is stored in Blob Storage in a format that can be easily processed by the forecasting model.

Azure Databricks:

This step is to use Azure Machine Learning to create a forecasting model that takes the data from Blob Storage and predicts future electricity consumption patterns. Machine Learning is a cloud-based service that allows users to build and deploy machine learning models. In this project, we use Machine Learning to create a forecasting model that predicts electricity consumption for the next 24 hours. The forecasting model can be used to optimize energy usage and reduce waste.



<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/bfc16105-90a4-4a09-8326-8bb0617183e0">









<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/e5a40ad1-fb4c-4417-bf8b-acb8efa7b0e3">









Event Stream:

This step is to use Stream Analytics to check for anomalies using the spike and dip algorithm. The algorithm is designed to detect sudden increases or decreases in energy consumption that could indicate a fault or malfunction in the system. If an anomaly is detected, Stream Analytics sends an alert to an Event Hub.




<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/82552795-0cbb-4bd1-b4e1-867c9a26ec63">








<img width="463" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/e078ff75-46b0-42f0-8311-b4e993947784">







Then Azure Logic Apps is used to trigger an email notification to the relevant stakeholders if an anomaly is detected. Logic Apps is a cloud-based service that allows users to create workflows that integrate various services and systems. In this project, we use Logic Apps to trigger an email notification to stakeholders via Gmail.





<img width="425" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/ab16a666-bfb9-4310-83c4-ebe38b9e0e11">







<img width="425" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/a4a54f9d-cde3-4996-9e7e-6ec45321c452">






## Data modeling

Azure Stream Analytics Spike and Dip Algorithm:

The Azure Stream Analytics Spike and Dip Algorithm is a machine learning-based algorithm that uses historical data to detect anomalies in real-time data streams. The algorithm works by analyzing the data stream and comparing it to historical data to identify any significant changes. The algorithm uses a statistical technique called z-score to determine the probability of a data point being an anomaly. The z-score is a measure of how many standard deviations a data point is away from the mean of the data set.
How the Algorithm Works:

The algorithm works by following these steps:

1. Data Ingestion:
The smart electricity meter readings are sent to Azure Stream Analytics for processing.
2. Data Preprocessing:
The data is preprocessed to remove any noise or irrelevant data.
3. Historical Data Analysis:
The algorithm analyzes the historical data to calculate the mean and standard deviation of the data set.
4. Real-time Data Analysis:
The algorithm compares the real-time data to the historical data to calculate the z-score.
5. Threshold Calculation:
The algorithm sets a threshold for the z-score to determine if a data point is an anomaly. The threshold is calculated based on the confidence level required for anomaly detection.
6. Anomaly Detection:
If a data point exceeds the threshold, it is flagged as an anomaly.
7. Alert Generation:
An alert is generated to notify the concerned stakeholders of the anomaly.
8. Detection of Spike and Dip in Voltage and Temperature:
To detect spikes and dips in voltage and temperature, the algorithm can be customized to use specific parameters for anomaly detection. The parameters can be set based on the expected range of voltage and temperature values. For example, if the expected range of voltage is between 220V to 240V, any data point that exceeds this range is flagged as an anomaly. Similarly, for temperature, the expected range can be set based on the weather conditions and the type of building.
The Azure Stream Analytics Spike and Dip Algorithm is an effective way to detect anomalies in smart electricity meter readings. By using historical data and statistical techniques, the algorithm can identify anomalies in real-time data streams. The algorithm can be customized to detect specific anomalies such as spikes and dips in voltage and temperature. This algorithm is a valuable tool for ensuring the reliability of energy consumption data, which is essential for energy providers and consumers alike.



Forecasting Consumption:
Adding a forecasting model to predict electricity consumption for the next day based on previous usage is a valuable addition to the anomaly detection system. There are several forecasting models available, but in this paper, we will discuss the AutoRegressive Integrated Moving Average (ARIMA) model, Prophet Model and how it can be used for electricity consumption forecasting.

ARIMA Model:
ARIMA is a time series forecasting model that is widely used in various industries, including energy, finance, and economics. The model uses historical data to identify trends and patterns in the time series and makes predictions based on those patterns. ARIMA consists of three components: Auto-Regression (AR), Integration (I), and Moving Average (MA). The AR component refers to the model's dependence on its own past values, the I component represents the differencing of the data to make it stationary, and the MA component refers to the model's dependence on past errors.

Using ARIMA for Electricity Consumption Forecasting:

To use ARIMA for electricity consumption forecasting, we need to follow the following steps:

1.Data Preprocessing: The historical data needs to be preprocessed to remove any noise or irrelevant data. The data needs to be in a time-series format, with each data point representing the consumption for a specific time period (e.g., hourly, daily, weekly).

	






2. Stationarity Check: The stationarity of the data needs to be checked, which means that the statistical properties of the data remain constant over time. If the data is not stationary, we need to perform differencing to make it stationary.
3. ARIMA Model Selection: The ARIMA model's parameters need to be selected, such as the number of Auto-Regression (AR) terms, Moving Average (MA) terms, and Integration (I) terms. We can use statistical tests such as Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to select the best-fit model.
4. Model Fitting: The ARIMA model needs to be fitted on the preprocessed data to generate forecasts for the next day's electricity consumption.
5. Forecasting: Once the model is fitted, it can be used to generate electricity consumption forecasts for the next day based on the historical data.
6. Evaluation: The forecasted values need to be evaluated against the actual consumption values to check the accuracy of the model. If the model's accuracy is not satisfactory, we need to adjust the parameters and retrain the model.



As our simulated data regularly contains anomalies, it is prone to outliers. Hence to deal with such data, a better model than ARIMA exists.
PROPHET Model:
Prophet is a valuable time-series forecasting model developed by Facebook's Core Data Science team. It offers several key features that make it particularly useful for business forecasting, such as the ability to model trends, seasonality, and holiday effects, as well as the inclusion of external variables that may impact the forecast.

Prophet employs a Bayesian approach to time-series forecasting, which allows for more flexibility in handling uncertainty and varying data patterns. This approach has gained popularity in both academic and business communities and has been widely applied in forecasting sales, website traffic, and other business metrics.

Prophet has many advantages, one of which is how simple it is to use and how little data preparation is needed. Its straightforward syntax and appealing forecast result displays make it usable by a variety of users.



<img width="388" alt="image" src="https://github.com/sandhyaAgolu15/Smart-Energy-Meters/assets/46163528/c9336504-d56b-4696-bd18-cceee1cd2a14">




Prophet is a robust and user-friendly time-series forecasting tool that might potentially provide considerable advantages to companies wishing to enhance their forecasting capabilities. It is an excellent complement to any forecasting effort because to its Bayesian methodology, adaptability, and capacity to handle external variables.

Implementation:

We have implemented the Prophet time-series forecasting model to predict electricity consumption for the next 24 hours. The data used for this model is collected by smart meters and sent to Azure IoT hub, where it is then stored in blob storage using a stream analytics job.

The Prophet model was implemented in a Data bricks notebook, which retrieved the collected data from the blob storage. The notebook included several steps to preprocess the data and fit the Prophet model. Firstly, the data was cleaned and formatted. Then, the variables to be used in the model were specified, and the model hyperparameters were tuned.

Once the Prophet model was fitted to the data, it was used to generate forecasts for the next 24 hours of electricity consumption. These forecasts were visualized in the notebook for further analysis and interpretation.



## Challenges:

Identifying relevant anomalies: 

Smart energy meter data is complex and includes many different types of anomalies. We have faced challenges in identifying anomalies. 

Setting appropriate thresholds: 

To detect anomalies, you need to set appropriate thresholds for what is considered abnormal behavior. Faced challenges in determining the appropriate thresholds for different types of anomalies and fine-tuning these thresholds over time.

Simulating large volumes of data: 

Simulating large volumes of Smart energy meter data was difficult part. Balancing false positives and false negatives: When detecting anomalies, balancing the risk of false positives (flagging normal data as anomalous) and false negatives (missing actual anomalies) is important. Faced challenges in finding the right balance and minimizing both types of errors.

## Future work:

Integration with renewable energy sources:

Smart meters can help facilitate the integration of renewable energy sources such as solar and wind power by providing real-time data on energy production and consumption, enabling homeowners and businesses to optimize their energy usage and reduce their dependence on the grid.

Improved data analytics:
 
With the vast amounts of data generated by smart meters, there is a need for advanced analytics tools to help energy providers and consumers make sense of the data and extract valuable insights. Future work in this area could focus on developing machine learning algorithms and predictive models to better forecast energy demand and optimize energy usage.

Enhanced cybersecurity: 

As smart meters become more ubiquitous, they also become an attractive target for hackers and cybercriminals. Future work in this area could focus on developing robust cybersecurity measures to protect smart meters and the data they generate from malicious attacks.

Create a Maintenance Plan: 

To make sure that the Smart Meter system is maintained current and that any faults are dealt with right away, a maintenance plan should be created. This needs to have a timetable for updates and upkeep, as well as a procedure for handling any problems that may occur.


Overall, the future of smart meters is exciting, with the potential to transform the way we use and think about energy. Continued research and development in this area will be critical to unlocking the full potential of this technology.






